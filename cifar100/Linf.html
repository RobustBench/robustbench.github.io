<table id="cifar100_leaderboard_Linf" class="datatable" style="width: 100%">
    <thead>
    <tr>
        <th class="rank">Rank</th>
        <th class="method">Method</th>
        <th class="ca">
            Standard<br/>
            accuracy
        </th>
        
        <th class="aa">
            AutoAttack<br/>
            robust<br/>
            accuracy
        </th>
        <th class="aa-ext">
            Best known<br/>
            robust<br/>
            accuracy
        </th>
        <th class="aa-ext">
            AA eval.<br/>
            potentially<br/>
            unreliable
        </th>
        
        
        
        <th class="extra-data">Extra <br/>data</th>
        <th class="arch">Architecture</th>
        <th class="venue">Venue</th>
    </tr>
    </thead>
    <tbody>
    
    <tr>
        <td class="ranktd">1</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2302.04638" target="_blank">Better Diffusion Models Further Improve Adversarial Training</a>
            
            <br>
            <span class="td-footer">
                It uses additional 50M synthetic images in training. 42.66% robust accuracy is given by MALT (Melamed et al., 2024).
            </span>
            
        </td>
        <td class="catd">75.22%</td>
        <td class="aatd">42.67%</td>
        <td class="aa-extd">42.66%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-70-16</td>
        <td class="venuetd">ICML 2023</td>
    </tr>
    
    <tr>
        <td class="ranktd">2</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2406.05927" target="_blank">MeanSparse: Post-Training Robustness Enhancement Through Mean-Centered Feature Sparsification</a>
            
            <br>
            <span class="td-footer">
                It adds the MeanSparse operator to the adversarially trained model Wang2023Better_WRN-70-16. 42.25% robust accuracy is due to APGD (both versions) with BPDA.
            </span>
            
        </td>
        <td class="catd">75.13%</td>
        <td class="aatd">44.78%</td>
        <td class="aa-extd">42.25%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        
        <td class="datatd">&#9745;</td>
        <td class="archtd">MeanSparse WideResNet-70-16</td>
        <td class="venuetd">arXiv, Jun 2024</td>
    </tr>
    
    <tr>
        <td class="ranktd">3</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2402.02263" target="_blank">MixedNUTS: Training-Free Accuracy-Robustness Balance via Nonlinearly Mixed Classifiers</a>
            
            <br>
            <span class="td-footer">
                It uses an ensemble of networks. The robust base classifier uses 50M synthetic images. 41.80% robust accuracy is due to the original evaluation (Adaptive AutoAttack)
            </span>
            
        </td>
        <td class="catd">83.08%</td>
        <td class="aatd">41.91%</td>
        <td class="aa-extd">41.80%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        
        <td class="datatd">&#9745;</td>
        <td class="archtd">ResNet-152 + WideResNet-70-16</td>
        <td class="venuetd">TMLR, Aug 2024</td>
    </tr>
    
    <tr>
        <td class="ranktd">4</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2305.13948" target="_blank">Decoupled Kullback-Leibler Divergence Loss</a>
            
            <br>
            <span class="td-footer">
                It uses additional 50M synthetic images in training.
            </span>
            
        </td>
        <td class="catd">73.85%</td>
        <td class="aatd">39.18%</td>
        <td class="aa-extd">39.18%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-28-10</td>
        <td class="venuetd">NeurIPS 2024</td>
    </tr>
    
    <tr>
        <td class="ranktd">5</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2302.04638" target="_blank">Better Diffusion Models Further Improve Adversarial Training</a>
            
            <br>
            <span class="td-footer">
                It uses additional 50M synthetic images in training. 38.77% robust accuracy is given by MALT (Melamed et al., 2024).
            </span>
            
        </td>
        <td class="catd">72.58%</td>
        <td class="aatd">38.83%</td>
        <td class="aa-extd">38.77%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-28-10</td>
        <td class="venuetd">ICML 2023</td>
    </tr>
    
    <tr>
        <td class="ranktd">6</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2301.12554" target="_blank">Improving the Accuracy-Robustness Trade-off of Classifiers via Adaptive Smoothing</a>
            
            <br>
            <span class="td-footer">
                It uses an ensemble of networks. The robust base classifier uses 50M synthetic images.
            </span>
            
        </td>
        <td class="catd">85.21%</td>
        <td class="aatd">38.72%</td>
        <td class="aa-extd">38.72%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        
        <td class="datatd">&#9745;</td>
        <td class="archtd">ResNet-152 + WideResNet-70-16 + mixing network</td>
        <td class="venuetd">SIMODS 2024</td>
    </tr>
    
    <tr>
        <td class="ranktd">7</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2010.03593" target="_blank">Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples</a>
            
        </td>
        <td class="catd">69.15%</td>
        <td class="aatd">36.88%</td>
        <td class="aa-extd">36.88%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        
        <td class="datatd">&#9745;</td>
        <td class="archtd">WideResNet-70-16</td>
        <td class="venuetd">arXiv, Oct 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">8</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2301.12554" target="_blank">Improving the Accuracy-Robustness Trade-off of Classifiers via Adaptive Smoothing</a>
            
            <br>
            <span class="td-footer">
                It uses an ensemble of networks.
            </span>
            
        </td>
        <td class="catd">80.18%</td>
        <td class="aatd">35.15%</td>
        <td class="aa-extd">35.15%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        
        <td class="datatd">&#9745;</td>
        <td class="archtd">ResNet-152 + WideResNet-70-16 + mixing network</td>
        <td class="venuetd">SIMODS 2024</td>
    </tr>
    
    <tr>
        <td class="ranktd">9</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2209.07399" target="_blank">A Light Recipe to Train Robust Vision Transformers</a>
            
        </td>
        <td class="catd">70.76%</td>
        <td class="aatd">35.08%</td>
        <td class="aa-extd">35.08%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        
        <td class="datatd">&#9745;</td>
        <td class="archtd">XCiT-L12</td>
        <td class="venuetd">arXiv, Sep 2022</td>
    </tr>
    
    <tr>
        <td class="ranktd">10</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2103.01946" target="_blank">Fixing Data Augmentation to Improve Adversarial Robustness</a>
            
            <br>
            <span class="td-footer">
                It uses additional 1M synthetic images in training.
            </span>
            
        </td>
        <td class="catd">63.56%</td>
        <td class="aatd">34.64%</td>
        <td class="aa-extd">34.64%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-70-16</td>
        <td class="venuetd">arXiv, Mar 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">11</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2209.07399" target="_blank">A Light Recipe to Train Robust Vision Transformers</a>
            
        </td>
        <td class="catd">69.21%</td>
        <td class="aatd">34.21%</td>
        <td class="aa-extd">34.21%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        
        <td class="datatd">&#9745;</td>
        <td class="archtd">XCiT-M12</td>
        <td class="venuetd">arXiv, Sep 2022</td>
    </tr>
    
    <tr>
        <td class="ranktd">12</td>
        <td class="methoddt">
            <a href="https://arxiv.org/pdf/2202.10103.pdf" target="_blank"> Robustness and Accuracy Could Be Reconcilable by (Proper) Definition</a>
            
            <br>
            <span class="td-footer">
                It uses additional 1M synthetic images in training.
            </span>
            
        </td>
        <td class="catd">65.56%</td>
        <td class="aatd">33.05%</td>
        <td class="aa-extd">33.05%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-70-16</td>
        <td class="venuetd">ICML 2022</td>
    </tr>
    
    <tr>
        <td class="ranktd">13</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2305.13948" target="_blank">Decoupled Kullback-Leibler Divergence Loss</a>
            
            <br>
            <span class="td-footer">
                It uses AutoAugment.
            </span>
            
        </td>
        <td class="catd">65.93%</td>
        <td class="aatd">32.52%</td>
        <td class="aa-extd">32.52%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-34-10</td>
        <td class="venuetd">NeurIPS 2024</td>
    </tr>
    
    <tr>
        <td class="ranktd">14</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2209.07399" target="_blank">A Light Recipe to Train Robust Vision Transformers</a>
            
        </td>
        <td class="catd">67.34%</td>
        <td class="aatd">32.19%</td>
        <td class="aa-extd">32.19%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        
        <td class="datatd">&#9745;</td>
        <td class="archtd">XCiT-S12</td>
        <td class="venuetd">arXiv, Sep 2022</td>
    </tr>
    
    <tr>
        <td class="ranktd">15</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2103.01946" target="_blank">Fixing Data Augmentation to Improve Adversarial Robustness</a>
            
            <br>
            <span class="td-footer">
                It uses additional 1M synthetic images in training.
            </span>
            
        </td>
        <td class="catd">62.41%</td>
        <td class="aatd">32.06%</td>
        <td class="aa-extd">32.06%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-28-10</td>
        <td class="venuetd">arXiv, Mar 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">16</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2305.13948" target="_blank">Decoupled Kullback-Leibler Divergence Loss</a>
            
        </td>
        <td class="catd">65.76%</td>
        <td class="aatd">31.91%</td>
        <td class="aa-extd">31.91%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-34-10</td>
        <td class="venuetd">NeurIPS 2024</td>
    </tr>
    
    <tr>
        <td class="ranktd">17</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2203.06616" target="_blank">LAS-AT: Adversarial Training with Learnable Attack Strategy</a>
            
            <br>
            <span class="td-footer">
                
            </span>
            
        </td>
        <td class="catd">67.31%</td>
        <td class="aatd">31.91%</td>
        <td class="aa-extd">31.91%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-34-20</td>
        <td class="venuetd">arXiv, Mar 2022</td>
    </tr>
    
    <tr>
        <td class="ranktd">18</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2210.15318" target="_blank">Efficient and Effective Augmentation Strategy for Adversarial Training</a>
            
        </td>
        <td class="catd">68.75%</td>
        <td class="aatd">31.85%</td>
        <td class="aa-extd">31.85%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-34-10</td>
        <td class="venuetd">NeurIPS 2022</td>
    </tr>
    
    <tr>
        <td class="ranktd">19</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2011.11164" target="_blank">Learnable Boundary Guided Adversarial Training</a>
            
            <br>
            <span class="td-footer">
                It is combined with AWP.
            </span>
            
        </td>
        <td class="catd">62.99%</td>
        <td class="aatd">31.20%</td>
        <td class="aa-extd">31.20%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-34-10</td>
        <td class="venuetd">ICCV 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">20</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2104.09425" target="_blank">Robust Learning Meets Generative Models: Can Proxy Distributions Improve Adversarial Robustness?</a>
            
            <br>
            <span class="td-footer">
                It uses additional 1M synthetic images in training.
            </span>
            
        </td>
        <td class="catd">65.93%</td>
        <td class="aatd">31.15%</td>
        <td class="aa-extd">31.15%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-34-10</td>
        <td class="venuetd">ICLR 2022</td>
    </tr>
    
    <tr>
        <td class="ranktd">21</td>
        <td class="methoddt">
            <a href="https://doi.org/10.1016/j.patcog.2024.110394" target="_blank">Data filtering for efficient adversarial training</a>
            
            <br>
            <span class="td-footer">
                
            </span>
            
        </td>
        <td class="catd">64.32%</td>
        <td class="aatd">31.13%</td>
        <td class="aa-extd">31.13%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-34-10</td>
        <td class="venuetd">Pattern Recognition 2024</td>
    </tr>
    
    <tr>
        <td class="ranktd">22</td>
        <td class="methoddt">
            <a href="https://arxiv.org/pdf/2202.10103.pdf" target="_blank"> Robustness and Accuracy Could Be Reconcilable by (Proper) Definition</a>
            
            <br>
            <span class="td-footer">
                It uses additional 1M synthetic images in training.
            </span>
            
        </td>
        <td class="catd">63.66%</td>
        <td class="aatd">31.08%</td>
        <td class="aa-extd">31.08%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-28-10</td>
        <td class="venuetd">ICML 2022</td>
    </tr>
    
    <tr>
        <td class="ranktd">23</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2203.06616" target="_blank">LAS-AT: Adversarial Training with Learnable Attack Strategy</a>
            
            <br>
            <span class="td-footer">
                
            </span>
            
        </td>
        <td class="catd">64.89%</td>
        <td class="aatd">30.77%</td>
        <td class="aa-extd">30.77%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-34-10</td>
        <td class="venuetd">arXiv, Mar 2022</td>
    </tr>
    
    <tr>
        <td class="ranktd">24</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2111.02331" target="_blank">LTD: Low Temperature Distillation for Robust Adversarial Training</a>
            
            <br>
            <span class="td-footer">
                
            </span>
            
        </td>
        <td class="catd">64.07%</td>
        <td class="aatd">30.59%</td>
        <td class="aa-extd">30.59%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-34-10</td>
        <td class="venuetd">arXiv, Nov 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">25</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2210.09852" target="_blank">Scaling Adversarial Training to Large Perturbation Bounds</a>
            
        </td>
        <td class="catd">65.73%</td>
        <td class="aatd">30.35%</td>
        <td class="aa-extd">30.35%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-34-10</td>
        <td class="venuetd">ECCV 2022</td>
    </tr>
    
    <tr>
        <td class="ranktd">26</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2011.11164" target="_blank">Learnable Boundary Guided Adversarial Training</a>
            
            <br>
            <span class="td-footer">
                Uses \(\ell_{\infty} \) = 0.031 ≈ 7.9/255 instead of 8/255
            </span>
            
        </td>
        <td class="catd">62.55%</td>
        <td class="aatd">30.20%</td>
        <td class="aa-extd">30.20%</td>
        <td class="flagsd">Unknown</td>
        
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-34-20</td>
        <td class="venuetd">ICCV 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">27</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2010.03593" target="_blank">Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples</a>
            
        </td>
        <td class="catd">60.86%</td>
        <td class="aatd">30.03%</td>
        <td class="aa-extd">30.03%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-70-16</td>
        <td class="venuetd">arXiv, Oct 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">28</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2011.11164" target="_blank">Learnable Boundary Guided Adversarial Training</a>
            
            <br>
            <span class="td-footer">
                Uses \(\ell_{\infty} \) = 0.031 ≈ 7.9/255 instead of 8/255
            </span>
            
        </td>
        <td class="catd">60.64%</td>
        <td class="aatd">29.33%</td>
        <td class="aa-extd">29.33%</td>
        <td class="flagsd">Unknown</td>
        
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-34-10</td>
        <td class="venuetd">ICCV 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">29</td>
        <td class="methoddt">
            <a href="https://openreview.net/forum?id=BuD2LmNaU3a" target="_blank">Helper-based Adversarial Training: Reducing Excessive Margin to Achieve a Better Accuracy vs. Robustness Trade-off</a>
            
            <br>
            <span class="td-footer">
                It uses additional 1M synthetic images in training.
            </span>
            
        </td>
        <td class="catd">61.50%</td>
        <td class="aatd">28.88%</td>
        <td class="aa-extd">28.88%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        
        <td class="datatd">&#215;</td>
        <td class="archtd">PreActResNet-18</td>
        <td class="venuetd">OpenReview, Jun 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">30</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2004.05884" target="_blank">Adversarial Weight Perturbation Helps Robust Generalization</a>
            
        </td>
        <td class="catd">60.38%</td>
        <td class="aatd">28.86%</td>
        <td class="aa-extd">28.86%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-34-10</td>
        <td class="venuetd">NeurIPS 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">31</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2103.01946" target="_blank">Fixing Data Augmentation to Improve Adversarial Robustness</a>
            
            <br>
            <span class="td-footer">
                It uses additional 1M synthetic images in training.
            </span>
            
        </td>
        <td class="catd">56.87%</td>
        <td class="aatd">28.50%</td>
        <td class="aa-extd">28.50%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        
        <td class="datatd">&#215;</td>
        <td class="archtd">PreActResNet-18</td>
        <td class="venuetd">arXiv, Mar 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">32</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/1901.09960" target="_blank">Using Pre-Training Can Improve Model Robustness and Uncertainty</a>
            
        </td>
        <td class="catd">59.23%</td>
        <td class="aatd">28.42%</td>
        <td class="aa-extd">28.42%</td>
        <td class="flagsd">Unknown</td>
        
        
        <td class="datatd">&#9745;</td>
        <td class="archtd">WideResNet-28-10</td>
        <td class="venuetd">ICML 2019</td>
    </tr>
    
    <tr>
        <td class="ranktd">33</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2210.15318" target="_blank">Efficient and Effective Augmentation Strategy for Adversarial Training</a>
            
        </td>
        <td class="catd">65.45%</td>
        <td class="aatd">27.67%</td>
        <td class="aa-extd">27.67%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        
        <td class="datatd">&#215;</td>
        <td class="archtd">ResNet-18</td>
        <td class="venuetd">NeurIPS 2022</td>
    </tr>
    
    <tr>
        <td class="ranktd">34</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2011.11164" target="_blank">Learnable Boundary Guided Adversarial Training</a>
            
            <br>
            <span class="td-footer">
                Uses \(\ell_{\infty} \) = 0.031 ≈ 7.9/255 instead of 8/255
            </span>
            
        </td>
        <td class="catd">70.25%</td>
        <td class="aatd">27.16%</td>
        <td class="aa-extd">27.16%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-34-10</td>
        <td class="venuetd">ICCV 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">35</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2210.09852" target="_blank">Scaling Adversarial Training to Large Perturbation Bounds</a>
            
        </td>
        <td class="catd">62.02%</td>
        <td class="aatd">27.14%</td>
        <td class="aa-extd">27.14%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        
        <td class="datatd">&#215;</td>
        <td class="archtd">PreActResNet-18</td>
        <td class="venuetd">ECCV 2022</td>
    </tr>
    
    <tr>
        <td class="ranktd">36</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2010.01278" target="_blank">Efficient Robust Training via Backward Smoothing</a>
            
        </td>
        <td class="catd">62.15%</td>
        <td class="aatd">26.94%</td>
        <td class="aa-extd">26.94%</td>
        <td class="flagsd">Unknown</td>
        
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-34-10</td>
        <td class="venuetd">arXiv, Oct 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">37</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2003.09347" target="_blank">Improving Adversarial Robustness Through Progressive Hardening</a>
            
        </td>
        <td class="catd">62.82%</td>
        <td class="aatd">24.57%</td>
        <td class="aa-extd">24.57%</td>
        <td class="flagsd">Unknown</td>
        
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-34-10</td>
        <td class="venuetd">arXiv, Mar 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">38</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2002.11569" target="_blank">Overfitting in adversarially robust deep learning</a>
            
        </td>
        <td class="catd">53.83%</td>
        <td class="aatd">18.95%</td>
        <td class="aa-extd">18.95%</td>
        <td class="flagsd">Unknown</td>
        
        
        <td class="datatd">&#215;</td>
        <td class="archtd">PreActResNet-18</td>
        <td class="venuetd">ICML 2020</td>
    </tr>
    
    </tbody>
</table>
<script>
    $(document).ready(function () {
        $("#cifar100_leaderboard_Linf").DataTable({
            lengthMenu: [15, 25, 50, 75, 100],
            "drawCallback": function (settings) {
                MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
            },
            language: {
                searchPlaceholder: "Papers, architectures, venues"
            },
            
            columnDefs: [
                { width: "15%", targets: 4 },
                { width: "15%", targets: 5 }
            ]
            
        });
    });
</script>
