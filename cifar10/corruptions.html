<table id="cifar10_leaderboard_corruptions" class="datatable" style="width: 100%">
    <thead>
    <tr>
        <th class="rank">Rank</th>
        <th class="method">Method</th>
        <th class="ca">
            Standard<br/>
            accuracy
        </th>
        
        
        <th class="aa">
            Robust <br/>
            accuracy
        </th>
        
        <th class="extra-data">Extra <br/>data</th>
        <th class="arch">Architecture</th>
        <th class="venue">Venue</th>
    </tr>
    </thead>
    <tbody>
    
    <tr>
        <td class="ranktd">1</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2104.01086" target="_blank">Defending Against Image Corruptions Through Adversarial Augmentations</a>
            
            <br>
            <span class="td-footer">
                Uses extra data indirectly via a super resolution and autoencoder networks that were pre-trained on other datasets.
            </span>
            
        </td>
        <td class="catd">94.93%</td>
        <td class="aatd">92.17%</td>
        
        <td class="datatd">&#9745;</td>
        <td class="archtd">ResNet-50</td>
        <td class="venuetd">arXiv, Apr 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">2</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2103.02325" target="_blank">On the effectiveness of adversarial training against common corruptions</a>
            
            <br>
            <span class="td-footer">
                Trained with RLAT and AugMix.
            </span>
            
        </td>
        <td class="catd">94.75%</td>
        <td class="aatd">89.60%</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">ResNet-18</td>
        <td class="venuetd">arXiv, Mar 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">3</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/1912.02781" target="_blank">AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty</a>
            
        </td>
        <td class="catd">95.83%</td>
        <td class="aatd">89.09%</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">ResNeXt29_32x4d</td>
        <td class="venuetd">ICLR 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">4</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/1912.02781" target="_blank">AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty</a>
            
        </td>
        <td class="catd">95.08%</td>
        <td class="aatd">88.82%</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-40-2</td>
        <td class="venuetd">ICLR 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">5</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2103.02325" target="_blank">On the effectiveness of adversarial training against common corruptions</a>
            
            <br>
            <span class="td-footer">
                Trained with RLAT and AugMix without the JSD term.
            </span>
            
        </td>
        <td class="catd">94.77%</td>
        <td class="aatd">88.53%</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">ResNet-18</td>
        <td class="venuetd">arXiv, Mar 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">6</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2103.01946" target="_blank">Fixing Data Augmentation to Improve Adversarial Robustness</a>
            
            <br>
            <span class="td-footer">
                Trained for \(\ell_2 \) robustness with \(\varepsilon = 0.5\).
            </span>
            
        </td>
        <td class="catd">92.23%</td>
        <td class="aatd">88.23%</td>
        
        <td class="datatd">&#9745;</td>
        <td class="archtd">WideResNet-70-16</td>
        <td class="venuetd">arXiv, Mar 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">7</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2010.03593" target="_blank">Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples</a>
            
            <br>
            <span class="td-footer">
                Trained for \(\ell_2 \) robustness with \(\varepsilon = 0.5\).
            </span>
            
        </td>
        <td class="catd">94.74%</td>
        <td class="aatd">87.68%</td>
        
        <td class="datatd">&#9745;</td>
        <td class="archtd">WideResNet-70-16</td>
        <td class="venuetd">arXiv, Oct 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">8</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2103.02325" target="_blank">On the effectiveness of adversarial training against common corruptions</a>
            
            <br>
            <span class="td-footer">
                Training with AugMix without the JSD term.
            </span>
            
        </td>
        <td class="catd">94.97%</td>
        <td class="aatd">86.60%</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">ResNet-18</td>
        <td class="venuetd">arXiv, Mar 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">9</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2103.02325" target="_blank">On the effectiveness of adversarial training against common corruptions</a>
            
            <br>
            <span class="td-footer">
                Trained with 50% Gaussian noise per batch. Note: Gaussian noise is contained in CIFAR-10-C.
            </span>
            
        </td>
        <td class="catd">93.24%</td>
        <td class="aatd">85.04%</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">ResNet-18</td>
        <td class="venuetd">arXiv, Mar 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">10</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2010.03593" target="_blank">Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples</a>
            
            <br>
            <span class="td-footer">
                Trained for \(\ell_2 \) robustness with \(\varepsilon = 0.5\).
            </span>
            
        </td>
        <td class="catd">90.90%</td>
        <td class="aatd">84.90%</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-70-16</td>
        <td class="venuetd">arXiv, Oct 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">11</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2103.02325" target="_blank">On the effectiveness of adversarial training against common corruptions</a>
            
            <br>
            <span class="td-footer">
                Trained with RLAT.
            </span>
            
        </td>
        <td class="catd">93.10%</td>
        <td class="aatd">84.10%</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">ResNet-18</td>
        <td class="venuetd">arXiv, Mar 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">12</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2103.01946" target="_blank">Fixing Data Augmentation to Improve Adversarial Robustness</a>
            
            <br>
            <span class="td-footer">
                Trained for \(\ell_{\infty} \) robustness with \(\varepsilon = 8/255\).
            </span>
            
        </td>
        <td class="catd">92.23%</td>
        <td class="aatd">82.82%</td>
        
        <td class="datatd">&#9745;</td>
        <td class="archtd">WideResNet-70-16</td>
        <td class="venuetd">arXiv, Mar 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">13</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2010.03593" target="_blank">Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples</a>
            
            <br>
            <span class="td-footer">
                Trained for \(\ell_{\infty} \) robustness with \(\varepsilon = 8/255\).
            </span>
            
        </td>
        <td class="catd">91.10%</td>
        <td class="aatd">81.84%</td>
        
        <td class="datatd">&#9745;</td>
        <td class="archtd">WideResNet-70-16</td>
        <td class="venuetd">arXiv, Oct 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">14</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2010.03593" target="_blank">Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples</a>
            
            <br>
            <span class="td-footer">
                Trained for \(\ell_{\infty} \) robustness with \(\varepsilon = 8/255\).
            </span>
            
        </td>
        <td class="catd">85.29%</td>
        <td class="aatd">76.37%</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-70-16</td>
        <td class="venuetd">arXiv, Oct 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">15</td>
        <td class="methoddt">
            <a href="https://github.com/RobustBench/robustbench/" target="_blank">Standardly trained model</a>
            
        </td>
        <td class="catd">94.78%</td>
        <td class="aatd">73.46%</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-28-10</td>
        <td class="venuetd">N/A</td>
    </tr>
    
    </tbody>
</table>
<script>
    $(document).ready(function () {
        $("#cifar10_leaderboard_corruptions").DataTable({
            lengthMenu: [15, 25, 50, 75, 100],
            "drawCallback": function (settings) {
                MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
            },
            language: {
                searchPlaceholder: "Papers, architectures, venues"
            },
            
        });
    });
</script>
