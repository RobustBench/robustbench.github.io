<table id="cifar10_leaderboard_L2" class="datatable" style="width: 100%">
    <thead>
    <tr>
        <th class="rank">Rank</th>
        <th class="method">Method</th>
        <th class="ca">
            Standard<br/>
            accuracy
        </th>
        
        <th class="aa">
            AutoAttack<br/>
            robust<br/>
            accuracy
        </th>
        <th class="aa-ext">
            Best known<br/>
            robust<br/>
            accuracy
        </th>
        <th class="aa-ext">
            AA eval.<br/>
            potentially<br/>
            unreliable
        </th>
        
        
        <th class="extra-data">Extra <br/>data</th>
        <th class="arch">Architecture</th>
        <th class="venue">Venue</th>
    </tr>
    </thead>
    <tbody>
    
    <tr>
        <td class="ranktd">1</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2103.01946" target="_blank">Fixing Data Augmentation to Improve Adversarial Robustness</a>
            
            <br>
            <span class="td-footer">
                
            </span>
            
        </td>
        <td class="catd">95.74%</td>
        <td class="aatd">82.32%</td>
        
        <td class="aa-extd">82.32%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        <td class="datatd">&#9745;</td>
        <td class="archtd">WideResNet-70-16</td>
        <td class="venuetd">arXiv, Mar 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">2</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2010.03593" target="_blank">Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples</a>
            
        </td>
        <td class="catd">94.74%</td>
        <td class="aatd">80.53%</td>
        
        <td class="aa-extd">80.53%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        <td class="datatd">&#9745;</td>
        <td class="archtd">WideResNet-70-16</td>
        <td class="venuetd">arXiv, Oct 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">3</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2103.01946" target="_blank">Fixing Data Augmentation to Improve Adversarial Robustness</a>
            
            <br>
            <span class="td-footer">
                It uses additional 1M synthetic images in training.
            </span>
            
        </td>
        <td class="catd">92.41%</td>
        <td class="aatd">80.42%</td>
        
        <td class="aa-extd">80.42%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-70-16</td>
        <td class="venuetd">arXiv, Mar 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">4</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2103.01946" target="_blank">Fixing Data Augmentation to Improve Adversarial Robustness</a>
            
            <br>
            <span class="td-footer">
                It uses additional 1M synthetic images in training.
            </span>
            
        </td>
        <td class="catd">91.79%</td>
        <td class="aatd">78.80%</td>
        
        <td class="aa-extd">78.80%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-28-10</td>
        <td class="venuetd">arXiv, Mar 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">5</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2003.09461" target="_blank">Adversarial Robustness on In- and Out-Distribution Improves Explainability</a>
            
        </td>
        <td class="catd">93.96%</td>
        <td class="aatd">78.79%</td>
        
        <td class="aa-extd">78.79%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#9745;</td>
        <td class="archtd">WideResNet-34-10</td>
        <td class="venuetd">ECCV 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">6</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2003.09461" target="_blank">Adversarial Robustness on In- and Out-Distribution Improves Explainability</a>
            
            <br>
            <span class="td-footer">
                Extra data used only as OOD dataset.
            </span>
            
        </td>
        <td class="catd">92.23%</td>
        <td class="aatd">76.25%</td>
        
        <td class="aa-extd">76.25%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#9745;</td>
        <td class="archtd">WideResNet-34-10</td>
        <td class="venuetd">ECCV 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">7</td>
        <td class="methoddt">
            <a href="https://openreview.net/forum?id=BuD2LmNaU3a" target="_blank">Helper-based Adversarial Training: Reducing Excessive Margin to Achieve a Better Accuracy vs. Robustness Trade-off</a>
            
            <br>
            <span class="td-footer">
                It uses additional 1M synthetic images in training.
            </span>
            
        </td>
        <td class="catd">90.57%</td>
        <td class="aatd">76.15%</td>
        
        <td class="aa-extd">76.15%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">PreActResNet-18</td>
        <td class="venuetd">OpenReview, Jun 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">8</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2104.09425" target="_blank">Improving Adversarial Robustness Using Proxy Distributions</a>
            
            <br>
            <span class="td-footer">
                It uses additional ~6M synthetic images in training.
            </span>
            
        </td>
        <td class="catd">90.31%</td>
        <td class="aatd">76.12%</td>
        
        <td class="aa-extd">76.12%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-34-10</td>
        <td class="venuetd">arXiv, Apr 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">9</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2103.01946" target="_blank">Fixing Data Augmentation to Improve Adversarial Robustness</a>
            
            <br>
            <span class="td-footer">
                It uses additional 1M synthetic images in training.
            </span>
            
        </td>
        <td class="catd">90.33%</td>
        <td class="aatd">75.86%</td>
        
        <td class="aa-extd">75.86%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">PreActResNet-18</td>
        <td class="venuetd">arXiv, Mar 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">10</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2010.03593" target="_blank">Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples</a>
            
        </td>
        <td class="catd">90.90%</td>
        <td class="aatd">74.50%</td>
        
        <td class="aa-extd">74.50%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-70-16</td>
        <td class="venuetd">arXiv, Oct 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">11</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2004.05884" target="_blank">Adversarial Weight Perturbation Helps Robust Generalization</a>
            
        </td>
        <td class="catd">88.51%</td>
        <td class="aatd">73.66%</td>
        
        <td class="aa-extd">73.66%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-34-10</td>
        <td class="venuetd">NeurIPS 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">12</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2104.09425" target="_blank">Improving Adversarial Robustness Using Proxy Distributions</a>
            
            <br>
            <span class="td-footer">
                It uses additional ~6M synthetic images in training.
            </span>
            
        </td>
        <td class="catd">89.52%</td>
        <td class="aatd">73.39%</td>
        
        <td class="aa-extd">73.39%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">ResNet-18</td>
        <td class="venuetd">arXiv, Apr 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">13</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2003.09461" target="_blank">Adversarial Robustness on In- and Out-Distribution Improves Explainability</a>
            
            <br>
            <span class="td-footer">
                Extra data used only as OOD dataset.
            </span>
            
        </td>
        <td class="catd">91.08%</td>
        <td class="aatd">72.91%</td>
        
        <td class="aa-extd">72.91%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#9745;</td>
        <td class="archtd">ResNet-50</td>
        <td class="venuetd">ECCV 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">14</td>
        <td class="methoddt">
            <a href="https://github.com/MadryLab/robustness" target="_blank">Robustness library</a>
            
        </td>
        <td class="catd">90.83%</td>
        <td class="aatd">69.24%</td>
        
        <td class="aa-extd">69.24%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">ResNet-50</td>
        <td class="venuetd">GitHub,<br>Sep 2019</td>
    </tr>
    
    <tr>
        <td class="ranktd">15</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2002.11569" target="_blank">Overfitting in adversarially robust deep learning</a>
            
        </td>
        <td class="catd">88.67%</td>
        <td class="aatd">67.68%</td>
        
        <td class="aa-extd">67.68%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">PreActResNet-18</td>
        <td class="venuetd">ICML 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">16</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/1811.09600" target="_blank">Decoupling Direction and Norm for Efficient Gradient-Based L2 Adversarial Attacks and Defenses</a>
            
        </td>
        <td class="catd">89.05%</td>
        <td class="aatd">66.44%</td>
        
        <td class="aa-extd">66.44%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-28-10</td>
        <td class="venuetd">CVPR 2019</td>
    </tr>
    
    <tr>
        <td class="ranktd">17</td>
        <td class="methoddt">
            <a href="https://openreview.net/forum?id=HkeryxBtPB" target="_blank">MMA Training: Direct Input Space Margin Maximization through Adversarial Training</a>
            
        </td>
        <td class="catd">88.02%</td>
        <td class="aatd">66.09%</td>
        
        <td class="aa-extd">66.09%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-28-4</td>
        <td class="venuetd">ICLR 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">18</td>
        <td class="methoddt">
            <a href="https://github.com/RobustBench/robustbench/" target="_blank">Standardly trained model</a>
            
        </td>
        <td class="catd">94.78%</td>
        <td class="aatd">0.0%</td>
        
        <td class="aa-extd">0.0%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-28-10</td>
        <td class="venuetd">N/A</td>
    </tr>
    
    </tbody>
</table>
<script>
    $(document).ready(function () {
        $("#cifar10_leaderboard_L2").DataTable({
            lengthMenu: [15, 25, 50, 75, 100],
            "drawCallback": function (settings) {
                MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
            },
            language: {
                searchPlaceholder: "Papers, architectures, venues"
            },
            
            columnDefs: [
                { width: "15%", targets: 4 },
                { width: "15%", targets: 5 }
            ]
            
        });
    });
</script>
